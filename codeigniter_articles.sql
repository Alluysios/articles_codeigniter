-- phpMyAdmin SQL Dump
-- version 4.8.0
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Apr 07, 2019 at 10:07 PM
-- Server version: 10.1.31-MariaDB
-- PHP Version: 7.2.4

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET AUTOCOMMIT = 0;
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `codeigniter_articles`
--

-- --------------------------------------------------------

--
-- Table structure for table `articles`
--

CREATE TABLE `articles` (
  `title` varchar(255) NOT NULL,
  `date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `description` text NOT NULL,
  `img` varchar(255) NOT NULL,
  `thumbnail` varchar(255) NOT NULL,
  `id` int(11) NOT NULL,
  `author_id` int(11) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Dumping data for table `articles`
--

INSERT INTO `articles` (`title`, `date`, `description`, `img`, `thumbnail`, `id`, `author_id`) VALUES
('Tim Berners-Lee on 30 years of the world wide web: \'We can get the web we want\'', '2019-04-07 02:58:26', 'Thirty years ago, Tim Berners-Lee, then a fellow at the physics research laboratory Cern on the French-Swiss border, sent his boss a document labelled Information Management: A Proposal. The memo suggested a system with which physicists at the centre could share “general information about accelerators and experiments”.\r\n\r\n“Many of the discussions of the future at Cern and the LHC era end with the question: ‘Yes, but how will we ever keep track of such a large project?’” wrote Berners-Lee. “This proposal provides an answer to such questions.”\r\n\r\nHis solution was a system called, initially, Mesh. It would combine a nascent field of technology called hypertext that allowed for human-readable documents to be linked together, with a distributed architecture that would see those documents stored on multiple servers, controlled by different people, and interconnected.\r\n\r\nIt didn’t really go anywhere. Berners-Lee’s boss, Mike Sendall, took the memo and jotted down a note on top: “Vague but exciting …” But that was it. It took another year, until 1990, for Berners-Lee to start actually writing code. In that time, the project had taken on a new name. Berners-Lee now called it the World Wide Web.\r\n\r\nThirty years on, and Berners-Lee’s invention has more than justified the lofty goals implied by its name. But with that scale has come a host of troubles, ones that he could never have predicted when he was building a system for sharing data about physics experiments.\r\n\r\nSome are simple enough. “Every time I hear that somebody has managed to acquire the [domain] name of their new enterprise for $50,000 (£38,500) instead of $500, I sigh, and feel that money’s not going to a good cause,” Berners-Lee tells me when we speak on the eve of the anniversary.', 'timberners.JPG', 'timberners_thumb.JPG', 31, 9),
('What I Wish I Knew Before I Learned to Code', '2019-04-07 03:01:41', 'I’ve been “coding” since I was a child. I didn’t think I was doing anything remarkable; I thought HTML was common knowledge back in the era of AOL 3.0 and Geocities. I used to spend hours creating websites (and graphics to adorn them), even though my AOL account had a time limit (thanks, parental controls) and I could only work on my websites for an hour a day.\r\n\r\nIf I couldn’t figure something out, I created a workaround. I had a workaround for everything. Looking back, I really pushed HTML to its limits.\r\n\r\nHTML made sense to me because I could see my work evolving as I added new lines of code. It was self-explanatory.\r\n\r\nBut like many children, I eventually forgot all about this hobby and moved on to other ventures.\r\n\r\nAs a teenager, I worked a summer job in IT… by accident. I had been hired to remove staples from documents to prepare them for scanning, but I always had free time, so they would throw extra projects my way. My supervisor would print out pages and pages of SQL and ask me to find the mistakes and correct them manually. It felt self-explanatory, too, so I did it with ease. Looking back, I have virtually no memories of what the code was expected to do, but I remember learning the syntax and finding typos all over the place.\r\n\r\nAnd then I moved on to other ventures.\r\n\r\nAs an adult, I built websites for my own projects, but never thought of doing web development as a career, until I began to see advertisements for coding academies. I had no idea what coding was, so I ignored the ads. At some point, though, I saw an ad for a coding academy that included a video… and then realized that “coding” is something I already had experience with.\r\n\r\nI breezed through the pre-bootcamp coursework, but on day 1 of the class, I found myself plagued with questions that would eventually prevent me from internalizing anything.\r\nI know myself. I can’t learn unless I understand why and how things operate. Before doing the pre-bootcamp coursework, the only thing I knew about JavaScript was that it’s blocked on school computers so that kids don’t play games, and if you don’t enable it, websites don’t always function as expected. By day 1, I could read and understand basic JavaScript, and I could regurgitate it with different variables, but I had no idea why I was doing it or what type of situations would prompt me to use these particular snippets of code.\r\n\r\nI knew right away that this would hold me back.\r\n\r\nAs the first day progressed, I filled a notebook with questions.\r\nHow do I know which language to choose for a particular application?\r\nWhy JavaScript? What sets it apart from other programming languages?\r\nWhy do people use Ruby for the back end and JavaScript for the front end? Could you theoretically use Ruby for the front end? Why or why not? Could you use JavaScript for the back end? Why or why not?\r\nHow do you create a programming language? Don’t you have to program it in another programming language?\r\nEach project on the syllabus has a checklist of requirements. Is this just to force us to use certain languages so that we can be assessed? Wouldn’t it be better to assign a project and make us use critical thinking skills to figure out which languages and frameworks we should be using?\r\nWhere exactly do I PUT the code when I’m done? Where do I put the JavaScript?\r\nI bombarded the instructor with these questions before we had even opened a text editor. I needed to understand the bigger picture before I could focus on the programming concepts. I knew that doing exercise after exercise wouldn’t help me retain anything. I needed to see the process from start to finish so that I could know what exactly I was working toward.\r\n\r\nAs the course went on, I memorized snippets of JavaScript to make pop-up alerts and other flashy features. I wasn’t really conceptualizing… I was just replicating what I had seen. I aced the object-oriented tasks, though.\r\n\r\nI remember offering a suggestion: “I really think future cohorts should start with object-oriented programming because it makes sense,” and being told, “I’m pretty sure you’re the only one who feels this way.”\r\n\r\nMy learning style ultimately affected the way I progressed through the program. I found myself using a variety of apps to practice Ruby and being able to transfer what I learned to my real-world projects. I studied JavaScript by reading and analyzing other people’s code. It was almost like learning a spoken language; I had to learn to read before I could write.', 'coding.jpg', 'coding_thumb.jpg', 32, 9),
('KV Storage: the Web\'s First Built-in Module', '2019-04-07 03:07:06', 'Browser vendors and web performance experts have been saying for the better part of the last decade that localStorage is slow, and web developers should stop using it.\r\n\r\nTo be fair, the people saying this are not wrong. localStorage is a synchronous API that blocks the main thread, and any time you access it you potentially prevent your page from being interactive.\r\n\r\nThe problem is the localStorage API is just so temptingly simple, and the only asynchronous alternative to localStorage is IndexedDB, which (let\'s face it) is not known for its ease of use or welcoming API.\r\n\r\nSo developers are left with a choice between something hard to use and something bad for performance. And while there are libraries that offer the simplicity of the localStorage API while actually using asynchronous storage APIs under the hood, including one of those libraries in your app has a file-size cost and can eat into your performance budget.\r\n\r\nBut what if it were possible to get the performance of an asynchronous storage API with the simplicity of the localStorage API, without having to pay the file size cost?\r\n\r\nWell, soon there may be. Chrome is experimenting with a new feature known as built-in modules, and the first one we\'re planning to ship is an asynchronous key/value storage module called KV Storage.\r\n\r\nBut before I get into the details of the KV Storage module, let me explain what I mean by built-in modules.\r\n\r\nWhat are built-in modules?\r\nBuilt-in modules are just like regular JavaScript modules, except that they don\'t have to be downloaded because they ship with the browser.\r\n\r\nLike traditional web APIs, built-in modules must go through a standardization process — each will have its own specification that requires a design review and positive signs of support from both web developers and other browser vendors before it can ship. (In Chrome, built-in modules will follow the same launch process we use to implement and ship all new APIs.)\r\n\r\nUnlike traditional web APIs, built-in modules are not exposed on the global scope — they\'re only available via imports.\r\n\r\nNot exposing built-in modules globally has a lot of advantages: they won\'t add any overhead to starting up a new JavaScript runtime context (e.g. a new tab, worker, or service worker), and they won\'t consume any memory or CPU unless they\'re actually imported. Furthermore, they don\'t run the risk of naming collisions with other variables defined in your code.\r\n\r\nTo import a built-in module you use the prefix std: followed by the built-in module\'s identifier. For example, in supported browsers, you could import the KV Storage module with the following code (see below for how to use a KV Storage polyfill in unsupported browsers):\r\n\r\nimport {storage, StorageArea} from \'std:kv-storage\';\r\nThe KV Storage module\r\nThe KV Storage module is similar in its simplicity to the localStorage API, but its API shape is actually closer to a JavaScript Map. Instead of getItem(), setItem(), and removeItem(), it has get(), set(), and delete(). It also has other map-like methods not available to localStorage, like keys(), values(), and entries(), and like Map, its keys do not have to be strings. They can be any structured-serializable type.\r\n\r\nUnlike Map, all KV Storage methods return either promises or async iterators (since the main point of this module is it\'s not synchronous, in contrast to localStorage). To see the full API in detail, you can refer to the specification.\r\n\r\nAs you may have noticed from the code example above, the KV Storage module has two named exports: storage and StorageArea.\r\n\r\nstorage is an instance of the StorageArea class with the name \'default\', and it\'s what developers will use most often in their application code. The StorageArea class is provided for cases where additional isolation is needed (e.g. a third-party library that stores data and wants to avoid conflicts with data stored via the default storage instance). StorageArea data is stored in an IndexedDB database with the name kv-storage:${name}, where name is the name of the StorageArea instance.\r\n\r\nHere\'s an example of how to use the KV Storage module in your code:\r\n\r\nimport {storage} from \'std:kv-storage\';\r\n\r\nconst main = async () => {\r\n  const oldPreferences = await storage.get(\'preferences\');\r\n\r\n  document.querySelector(\'form\').addEventListener(\'submit\', async () => {\r\n    const newPreferences = Object.assign({}, oldPreferences, {\r\n      // Updated preferences go here...\r\n    });\r\n\r\n    await storage.set(\'preferences\', newPreferences);\r\n  });\r\n};\r\n\r\nmain();\r\nNote: The KV Storage module is currently available in Chrome 74 if you have the experimental web platform features flag turned on: (chrome://flags/#enable-experimental-web-platform-features).\r\nWhat if a browser doesn\'t support a built-in module?\r\nIf you\'re familiar with using native JavaScript modules in browsers, you probably know that (at least up until now) importing anything other than a URL will generate an error. And std:kv-storage is not a valid URL.\r\n\r\nSo that raises the question: do we have to wait until all browsers support a built-in module before we can use it in our code? Thankfully, the answer is no!\r\n\r\nYou can actually use built-in modules as soon as even one browser supports them thanks to the help of another feature we\'re experimenting with called import maps.\r\n\r\nImport maps\r\nImport maps are essentially a mechanism by which developers can alias import identifiers to one or more alternate identifiers.\r\n\r\nThis is powerful because it gives you a way to change (at runtime) how a browser resolves a particular import identifier across your entire application.\r\n\r\nIn the case of built-in modules, this allows you to reference a polyfill of the module in your application code, but a browser that supports the built-in module can load that version instead!\r\n\r\nHere\'s how you would declare an import map to make this work with the KV Storage module:\r\n\r\n<!-- The import map is inlined into your page -->\r\n<script type=\"importmap\">\r\n{\r\n  \"imports\": {\r\n    \"/path/to/kv-storage-polyfill.mjs\": [\r\n      \"std:kv-storage\",\r\n      \"/path/to/kv-storage-polyfill.mjs\"\r\n    ]\r\n  }\r\n}\r\n</script>\r\n\r\n<!-- Then any module scripts with import statements use the above map -->\r\n<script type=\"module\">\r\n  import {storage} from \'/path/to/kv-storage-polyfill.mjs\';\r\n\r\n  // Use `storage` ...\r\n</script>\r\nThe key point in the above code is the URL /path/to/kv-storage-polyfill.mjs is being mapped to two different resources: std:kv-storage and then the original URL again, /path/to/kv-storage-polyfill.mjs.\r\n\r\nSo when the browser encounters an import statement referencing that URL (/path/to/kv-storage-polyfill.mjs), it first tries to load std:kv-storage, and if it can\'t then it falls back to loading /path/to/kv-storage-polyfill.mjs.\r\n\r\nAgain, the magic here is that the browser doesn\'t need to support import maps or built-in modules for this technique to work since the URL being passed to the import statement is the URL for the polyfill. The polyfill is not actually a fallback, it\'s the default. The built-in module is a progressive enhancement!\r\n\r\nWhat about browsers that don\'t support modules at all?\r\nIn order to use import maps to conditionally load built-in modules, you have to actually use import statements, which also means you have to use module scripts, i.e. <script type=\"module\">.\r\n\r\nCurrently, more than 80% of browsers support modules, and for browsers that don\'t, you can use the module/nomodule technique to serve a legacy bundle to older browsers. Note that when generating your nomodule build, you\'ll need to include all polyfills because you know for sure that browsers that don\'t support modules will definitely not support built-in modules.', 'modules.jpg', 'modules_thumb.jpg', 34, 9),
('How a Googler solves coding problems', '2019-04-07 03:12:36', 'In this article, I’ll walk you through my strategy for solving programming problems from start to finish, which I use both in my daily work at Google and with programmers of all levels (bootcampers, university students, and interns alike) as they learn and grow. Applying this structured process minimizes the frustrating debugging process and leads to cleaner, more correct code in less time.\r\n\r\nStep By Step\r\nI’ll be using an example practice problem to illustrate.\r\n\r\nProblem: “Given two strings, sourceString and searchString, return the first index at which searchString occurs within sourceString. If searchString does not occur within sourceString, return -1.\r\n\r\n1) Draw it.\r\nTrying to start by immediately writing code is frankly a ridiculous and lazy idea. Before you write an essay, you start by figuring out a hypothesis and evidence and ensuring that the argument makes sense. If you don’t, you’ll waste time starting over later when you realize what you’ve written doesn’t fit together cohesively. Code is the same way, except worse. Like, the rubbing-shampoo-in-your-eyes kind of worse.\r\n\r\nOften the solution to a problem is not trivial, even if it appears simple at first glance. Working it out on paper allows you to figure out a solution and verify that the solution works in a few different situations, all before even writing a single line of code.\r\n\r\nSo don’t write code. Don’t even think about code. You’ll have plenty of time to add the semicolons and parentheses later. Just try to figure out how you, as a human computer, solve the problem.\r\n\r\nDraw pictures. Use arrows. Put numbers into little boxes. Whatever helps you visualize the problem, do that. The goal is to problem-solve, and you have all the freedom of paper and pencil, with none of the constraints of a keyboard.\r\n\r\nStart by inventing some simple inputs. If the function “takes a string”, \"abc\" makes a great first example. Figure out what the correct result should be. Then, try to think about *how* you figured out the problem, and the steps that were involved.\r\n\r\nLet’s imagine the strings have these values:\r\n\r\nsourceString: \"abcdyesefgh\"\r\nsearchString: \"yes\"\r\nMy thoughts, verbatim:\r\nOkay, so I can see that searchString is inside of sourceString. But how did I do that? Well, I started at the beginning of sourceString and read through it until I reached the end, looking at every 3-character piece to see if it matched the word\"yes\". For example, \"abc\", \"bcd\", \"cde\", and so on. When I got to index 4, I found \"yes\", and so I decided that there is a match, and it starts at index 4.\r\n\r\nWhen we write down our algorithm, we need to make sure we express everything and handle all the possible scenarios. Returning the right answer when we DO find a match is nice, but we also need to return the right answer when we DON’T find a match.\r\n\r\nLet’s try again with another pair of strings:\r\n\r\nsourceString: \"abcdyefg\"\r\nsearchString: \"yes\"\r\nHere, we started at the beginning of sourceString and read through it until we reached the end, looking at every 3-character piece to see if it matched the word \"yes\". When we got to index 4, we found \"yef\", which was almost a match, but it wasn’t completely a match, since the third character was different. So we kept going until we reached the end of the string, and then decided there wasn’t a match, so we returned -1.\r\n\r\nWe’ve identified the series of steps (in programming, we call this an algorithm) that we take to solve the problem, and we’ve tried it in a couple of different scenarios, getting the correct result each time. At this point, we can have some confidence that our algorithm works, and so now it’s time to formalize the algorithm, bringing us to the next step:\r\n\r\n2) Write it in English.\r\nHere, we think about the algorithm I identified in step 1), and try to write it out in English. This makes the steps concrete, so that we can refer back to it later when writing the code.\r\n\r\nStart at the beginning of the string.\r\nLook at each set of 3 characters (or however many characters there are in searchString).\r\nIf any of them are equal to searchString, return the current index.\r\nIf we get to the end of the string without anything matching, return -1.\r\nSeems good!\r\n\r\n3) Write pseudocode.\r\nPseudocode isn’t really code, but it mimics the structure of code. Here’s how I would write a pseudocode version of my algorithm above:\r\n\r\nfor each index in sourceString,\r\n    there are N characters in searchString\r\n    let N chars from index onward be called POSSIBLE_MATCH\r\n    if POSSIBLE_MATCH is equal to searchString, return index\r\nat the end, if we haven\'t found a match yet, return -1.\r\nI could go a bit closer to code by writing it this way:\r\n\r\nfor each index in sourceString,\r\n    N = searchString.length\r\n    POSSIBLE_MATCH = sourceString[index to index+N]\r\n    if POSSIBLE_MATCH === searchString:\r\n        return index\r\nreturn -1\r\nHow much your pseudocode resembles code is up to you, and over time you’ll discover the way that works best for you!\r\n\r\n4) Translate what you can to code.\r\nNote: For easier problems, this can be combined with the step above.\r\n\r\nThis is the first time in the process that we have to worry about syntax, function parameters and language rules. Maybe you can’t write everything out, and that’s okay. Write in the pieces that you know!\r\n\r\nfunction findFirstMatch(searchString, sourceString) {\r\n    let length = searchString.length;\r\n    for (let index = 0; index < sourceString.length; index++) {\r\n        let possibleMatch = <the LENGTH chars starting at index i>\r\n        if (possibleMatch === searchString) {\r\n            return index;\r\n        }\r\n    }\r\n    return -1;\r\n}\r\nNotice that I left part of this code blank. This is intentional! I wasn’t sure of the syntax for slicing strings in JavaScript, so I’ll go look it up in the next step.\r\n\r\n5) Don’t guess.\r\nA common mistake I see in new coders is the practice of finding something on the internet, saying “maybe this will work”, and plugging it into your program without testing it. The more pieces of your program you don’t understand, the less likely you are to end up with the right solution.\r\n\r\nThe number of ways that your program can be incorrect DOUBLES with every new thing you are not sure about. Not sure about 1 thing? Great?—?if your code doesn’t work, only 1 thing can be the culprit.\r\n\r\nBut 2 things? 3 possibilities (thing A is broken, or thing B is broken, or both are broken!). 3 things? 7 possibilities. It quickly spirals out of control.\r\n\r\nSide note: The formula for ways in which your program can be wrong follows the Mersenne sequence. a(n) = (2^n)?—?1\r\n\r\nTest your new code first. Finding something on the internet is great, but before you plug it into your program, test it in a small, separate space to make sure it works in the way that you think it does.\r\n\r\nIn the previous step, I wasn’t sure of the way to select a certain part of a string in JavaScript. So off I go to Google:\r\n\r\nhttps://www.google.com/search?q=how+to+select+part+of+a+string+in+javascript\r\n\r\nThe first result is from w3schools. A bit dated, but usually dependable.\r\nhttps://www.w3schools.com/jsref/jsref_substr.asp\r\n\r\nBased on this, I assume that I should use \r\nsubstr(index, searchString.length) \r\nto extract the portion of sourceString each time. But it’s an assumption, nothing more. So first, I create a small example to test the behavior.\r\n\r\n>> let testStr = \"abcdefghi\"\r\n>> let subStr = testStr.substr(3, 4);  // simple, easy usage\r\n>> console.log(subStr);\r\n\"defg\"\r\n>> subStr = testStr.substr(8, 5);   // ask for more chars than exist\r\n\"i\"\r\nNow I am sure of how this function behaves. So when I plug this into my program, I know that if my program doesn’t work, it’s not the new piece I added that’s misbehaving.\r\n\r\nAnd with that, I can plug in the final piece of my program.\r\n\r\nfunction findFirstMatch(searchString, sourceString) {\r\n    let length = searchString.length;\r\n    for (let index = 0; index < sourceString.length; index++) {\r\n        let possibleMatch = (\r\n            sourceString.substr(index, length));\r\n        if (possibleMatch === searchString) {\r\n            return index;\r\n        }\r\n    }\r\n    return -1;\r\n}\r\nConclusion\r\nIf you’ve read to the end, all I can say now is: try it. Go back to that programming problem that you set aside last week in frustration. I guarantee you’ll see immediate improvement.\r\n\r\nGood luck, and happy coding!', 'google.jpg', 'google_thumb.jpg', 35, 11),
('The State of UX  in 2019', '2019-04-07 03:37:45', 'We have seen quite a lot this year. After curating and sharing 2,239 links with 264,016 designers around the world, we have isolated a few trends in what our industry is writing, talking, and thinking about. Here’s what to expect for UX in 2019.\r\n\r\nFrom the editors\r\n\r\nIf you landed here hoping to find out whether rounded corners and brutalist typefaces will be trending in 2019, we have some bad news. This is not an article about UI trends — you’ll find those on Medium every week, produced by specialized publications. \r\n\r\nOur annual report is a holistic analysis of UX Design as a discipline: the tools we use, the methods we apply every day, the technologies we design around, the career challenges we experience, and how our community is responsible for what\'s happening in the world around us — the one that we, consciously or not, have helped design. \r\n\r\nThis is the fourth year in a row that we’re publishing our trends report (which has us wondering—at what point exactly does something become a tradition?). The response we received last year was so overwhelmingly positive it inspired us to go even further in our exploration. We embarked upon this year’s report knowing that we must be even more critical of our work, with a deeper awareness of our responsibility as designers and an understanding of our broader impact on society.\r\n\r\nWe are looking forward to how design will evolve in 2019. Meanwhile, here is our review of the past and analysis of the present, with an ever-watchful eye on the future of UX.\r\n\r\nHope you enjoy the ride,\r\n\r\nFabricio + Caio\r\n\r\nEveryone is a lead\r\nYou’ve finally scored that “Design Lead” title. Exciting, right? Until you look around and see that everyone else has a similar title. When everyone is a lead, is anyone a lead?\r\nA decade ago, most designers were new to digital design. Two decades ago, everyone was new. There was something exciting about being the trailblazers helping to define how User Experience, as a profession, would evolve.\r\n\r\nDesigners are getting old. Today, it’s not uncommon to find folks with 15 or 20 years of professional experience in digital design. These are the people who have evolved their craft over the course of time to adapt to new processes and tools; they’ve taken leadership roles in our industry to help train and shape the next generation of designers.\r\n\r\nHowever, the way we break down job title requirements by level is rapidly becoming antiquated. Generally, in the United States, it goes like this: after two years Associate Designers become Mid-level Designers; after four years they become Senior Designers; after six they become Lead Designers. Not to mention the recent phenomenon of designers who acquire a Senior title less than a year after school. \r\n\r\nCredit:  The Design Team , by the awesome Pablo Stanley\r\nCredit: The Design Team, by the awesome Pablo Stanley\r\n\r\nSince the rise of bootcamp design schools in the early 2010s, thousands of new designers are entering the market each year, a faster turnaround time than that of graduates who enter the workforce after completing traditional education programs. And all of them are now getting their highly anticipated Design Lead title.\r\n\r\nWe are building an industry full of lead- and director-level designers. The current ratio between managers and individual contributors is so unbalanced that it\'s not uncommon to find managers/leads of teams of one.\r\nIn the long run, that top-heavy structure might not be sustainable. Paying lead/director salaries to individual contributors inflates our industry, while fancy job titles create the false expectation that someone is being hired to manage and not to produce designs — leading to frustration and low retention rates. To help fix that, some companies have been creating official documentation that outlines roles and responsibilities for each level to avoid mismatched expectations.\r\n\r\nEveryone is looking for Seniors\r\nEveryone is looking for Seniors\r\n\r\nFrom a high-level perspective, we are seeing a clear differentiation between the seniority levels implied in job titles and the actual impact designers are having in their organization. \r\n\r\nSeniority levels used for job titles. Associate, Mid-level, Senior, Lead, Manager, Director, Group Director, VP. The list of titles for designers continues to expand, with new labels and levels and variations continually added. The goal is to attract new hires who are on the lookout for a senior-sounding position, while keeping current employees motivated, rewarding them with a shiny new position every other year.\r\n\r\nIndependence and power within an organization. Although unspoken, company heads are starting to think about their employees in two main buckets: juniors and leaders (which certainly do not map to the title “Associate” or “Senior” titles from the first group). Seniority is becoming less about years of experience on your resume and more about your mindset, your behaviors, and your ability to influence change in the organization, whether that’s through state-of-art interfaces or pure thought leadership and articulation.\r\n\r\nIn 2019 we should start looking at seniority through new lenses. You can be proud of your “lead” title, as it is an integral part of your growth story. But if you consider seniority from the perspective of how much impact you are able to make (or not) within your organization, you’ll have a better sense of where you are along your career trajectory and of how your particular skills and experience are influencing others around you and our industry as a whole.\r\n\r\n', 'uxdesign.jpg', 'uxdesign_thumb.jpg', 37, 11),
('Everything I know about freelancing', '2019-04-07 03:40:27', 'You’ve probably read a lot about freelancing: Feast and famine. Where to find clients. How much to charge. These topics are fundamental, but it seems like most freelancers burn out before they get over these hurdles. Can freelancing be a stable, long-term career?\r\n\r\nI think so! I’ve been freelancing for 7 years, which is long enough to have survived lots of ups, downs, and evolutions of my business. Certainly Software has grown 5x in those years, and has gone from literally starting in a barn loft to now having a ground-level office in a much nicer barn.\r\n\r\nAm I getting the hang of it? Maybe! Or is the market just uber hot, so schmucks like me can’t miss? Probably! Either way, I’ve learned quite a bit over the years through pain, success, and failure.\r\n\r\nBelow is everything I’ve learned, loosely grouped by topic. I was very much inspired by Jason Cohen’s Kung Fu post. This is my style of freelancing kung fu – other freelancers have different styles. Maybe something here will work for you, maybe not. Let’s begin.\r\n\r\nBilling and Rates\r\nThe most challenging part about freelancing is not technical, it’s growing the business. Spend your time and set your rates accordingly. 50% of your time on business development is not too much!\r\n\r\nDon’t bill hourly. Bill by day or by week. Billing a daily rate allows you to avoid wasting time tracking time, and makes it a lot easier to focus on 1 project at a time. Estimates are also much easier to make in daily increments. The exception is retainers: Those can be hourly, but charge accordingly.\r\n\r\nYou can specialize simply in charging more (thanks tptacek). Imagine two projects which are effectively the same work, except one has a budget 10x the other. Specialize in the 10x projects.\r\n\r\nWhy do some projects have 10x the budget? Sometimes it’s just because the client has more money. But mostly: Larger companies can’t afford (the risks associated with) cheap freelancers. “You get what you pay for” applies to freelancers as well, which is why large companies will prefer larger, established agencies even though they cost a lot.\r\n\r\nTake your finely-calculated estimate and 3x it, both in time and money.\r\n\r\nYou should get really comfortable with “no”; Both saying “no” to bad fits, and hearing “no” from clients who can’t afford you.\r\n\r\nYou’re probably undercharging. Charge more (thanks patio11), but also be at peace if you’re making enough right now. It’s easy to excessively worry about leaving money on the table. Everyone does it. There’s always a next project.\r\n\r\nHigh rates have a compounding benefit.\r\nLow rates = more time working = less time selling = low rates.\r\nHigh rates = less time working = more time selling = higher rates.\r\nRaising your rates allows you more time to focus on raising your rates.\r\n\r\nSave a little time each month for emergency projects, and charge accordingly.\r\n\r\nIf you need help determining rates, find the highest-paying job you could realistically get (regardless of location) and charge more than that. Here’s a formula I came up with for this.\r\n\r\nYou’d be shocked at how much money large companies spend on simple static websites or CRUD apps that are often mediocre and/or thrown away. Similarly, you’d be shocked on how much money companies spend on consultants for advice, only to not implement (or even read!) the recommendations they’re given because the consultants half-assed it. You can do better!\r\n\r\nTalk about budget early in the conversation. It’s sometimes uncomfortable, but you’ll save everyone lots of time by determining if you’re even in the same ballpark. You won’t lose good contracts by talking about budget, and you shouldn’t be afraid of scaring away low-budget clients.\r\n\r\nYou don’t get PTO, so it will feel like you’re losing money when you take a vacation. It’s strange.\r\n\r\nAlways bill, even for small fixes. If you work for free, you are setting expectations for clients and they will take advantage of the freebies. On the flip side, you can do favors for long-term clients if you know they won’t try to exploit you. Don’t nickel & dime the client that is giving you 50% of your work!\r\n\r\nLearning how to move to high-rate freelancing is part experience, part simply having the guts to charge more and hear “no” from clients. High-rate freelancers have learned the business value of what they provide. If you freelance long enough and are observant, you’ll learn what matters & what doesn’t matter to clients.\r\n\r\nMake it as easy as possible for clients to pay. Don’t get hung up trying to save 3% credit card processing fees! Do whatever it takes to smooth the process of them paying you, including registering on their wacky billing system if needs be.\r\n\r\nCollect payment (50% – 100%) before starting work, particularly for new clients you’re not comfortable with. You can make exceptions for large or repeat clients whom you’re confident will pay.\r\n\r\nExpect late payments. Don’t hesitate to politely nag, they probably just forgot. The squeaky wheel gets greased.\r\n\r\nYour clients won’t realize they’ll need maintenance on their project unless you tell them. Include maintenance as part of every proposal, lest the client spends their whole budget on building the first version.\r\n\r\nBecause you’re independent and can build things, “idea” people are going to come to you all the time with partnership proposals. Feel free to listen, but 99% of these are worthless – particularly if you’ve only just met the person.\r\n\r\non codepen\r\n\r\nDealing with Clients\r\nClients generally fall into 2 buckets: “Price-isn’t-a-big-concern” and “extremely-price-sensitive”. It’s all in how the client views their project: Is it a profit-center or cost-center? I’ve found very little middle ground. Identify the high-value clients, and focus your business on them exclusively.\r\n\r\nThere is nothing like in-person meetings to strengthen relationships. That being said, I’ve only met ~3 of my dozens of clients in person, so it’s not utterly critical.\r\n\r\nYou don’t have to like the people you work with, but it sure helps. My best clients have been the ones I’ve had good personal connections with.\r\n\r\nAn incomplete list of red flags:\r\n\r\nIf a potential client tells you how something should be implemented, they don’t want you to think too much and don’t value your expertise.\r\nIf a client previously posted their projects to Fiverr or UpWork, it’s a signal they don’t value expertise.\r\nIf a client won’t listen to your advice because something is not your speciality, they probably see you as an implementer, not a partner. You probably sold yourself short and/or the client doesn’t value you like they should.\r\nIf a client tells you how long a project should take you to finish, they think they know an awful lot about your field.\r\nIf a potential client can’t explain why they chose you to talk to (i.e. for your expertise, because of an article they read, because of a referral, etc), they’re probably shopping around and you’re bidding against other contractors. This isn’t the worst thing in the world, but you’ll have minimal leverage.\r\nIf a client starts asking for detailed breakdowns of your time spent when they haven’t asked in the past, you’re probably being viewed as too expensive and should brace for an end or change to the relationship.\r\nDon’t hesitate to speak up if you know something better than your client – even if it’s not necessarily what they’re paying for. Just be sure you actually know what you’re talking about, and take time to craft your message to them.\r\n\r\nDon’t pretend to know stuff you don’t actually know. You’re not good at BSing, and BSers lose credibility really fast. Instead, don’t be afraid to say “I’m not sure, but I’ll do some research and find out”.\r\n\r\nYour first interactions with anyone will set the tone for the rest of the relationship. If you crush the first emails, phone calls, or meetings, your reputation will be solidified for the long-term.\r\n\r\nIdentify your “champion” within larger organizations – someone who will advocate for you. They are worth a lot – do them favors and you’ll find your invoices will get paid faster, more work will come your way, and you’ll have staying power within the organization. Often this person is the one who benefits most from your work or someone who felt the most pain before you came along.\r\n\r\nBe kind & professional to everyone you interact with at a client, even if they’re not your main point of contact. Remember names. Sure, it’s a good thing to do in general, but it helps business as well: People move to new companies and will recommend you. Never never never never burn bridges.\r\n\r\nFor more information refer: https://andyadams.org/everything-i-know-about-freelancing', 'freelancer.jpg', 'freelancer_thumb.jpg', 38, 11),
('Understanding Design Patterns in JavaScript', '2019-04-07 04:25:59', 'When you start a new project, you don’t immediately start coding. You first have to define the purpose and scope of the project, then list out the project features or specs. After you can either start coding or if you are working on a more complex project then you should choose a design pattern that best suits your project.\r\n\r\nWhat is a Design Pattern?\r\nIn software engineering, a design pattern is a reusable solution for commonly occurring problems in software design. Design patterns represent the best practices used by the experienced software developers. A design pattern can be thought of as a programming template.\r\n\r\nWhy use Design Patterns?\r\nMany programmers either think design patterns are a waste of time or they don’t know how to apply them appropriately. But using an appropriate design pattern can help you to write better and more understandable code, and the code can be easily maintained because it’s easier to understand.\r\n\r\nMost importantly, the design patterns give software developers a common vocabulary to talk about. They show the intent of your code instantly to someone learning the code.\r\n\r\nFor example, if you are using decorator pattern in your project, then a new programmer would immediately know what that piece of code is doing, and they can focus more on solving the business problem rather than trying to understand what that code is doing.\r\n\r\nNow that we know what design patterns are, and why they are important, let’s dive into various design patterns used in JavaScript.\r\n\r\nModule Pattern\r\nA Module is a piece of self-contained code so we can update the Module without affecting the other parts of the code. Modules also allow us to avoid namespace pollution by creating a separate scope for our variables. We can also reuse modules in other projects when they are decoupled from other pieces of code.\r\n\r\nModules are an integral part of any modern JavaScript application and help in keeping our code clean, separated and organized. There are many ways to create modules in JavaScript, one of which is Module pattern.\r\n\r\nTip: Use Bit to build faster with components. It helps your team share and reuse components, and use them to build new applications. Give it a try.\r\n\r\nUnlike other programming languages, JavaScript doesn’t have access modifiers, that is, you can’t declare a variable as private or public. So the Module pattern is also used to emulate the concept of encapsulation.\r\n\r\nThis pattern uses IIFE (immediately-invoked function expression), closures and function scope to simulate this concept. For example:\r\n\r\nconst myModule = (function() {\r\n  \r\n  const privateVariable = \'Hello World\';\r\n  \r\n  function privateMethod() {\r\n    console.log(privateVariable);\r\n  }\r\n  return {\r\n    publicMethod: function() {\r\n      privateMethod();\r\n    }\r\n  }\r\n})();\r\nmyModule.publicMethod();\r\nAs it’s IIFE, the code is immediately executed, and the returned object is assigned to the myModule variable. Due to closures, the returned object can still access the functions and variables defined inside the IIFE even after when IIFE has finished.\r\n\r\nSo the variables and functions defined inside the IIFE are essentially hidden from the outer scope and thus making it private to the myModule variable.\r\n\r\nAfter the code is executed, the myModule variable looks like this:\r\n\r\nconst myModule = {\r\n  publicMethod: function() {\r\n    privateMethod();\r\n  }};\r\nSo we can call the publicMethod() which will, in turn, call the privateMethod(). For example:\r\n\r\n// Prints \'Hello World\'\r\nmodule.publicMethod();\r\nRevealing Module Pattern\r\nThe Revealing Module pattern is a slightly improved version of the module pattern by Christian Heilmann. The problem with the module pattern is that we have to create new public functions just to call the private functions and variables.\r\n\r\nIn this pattern, we map the returned object’s properties to the private functions that we want to reveal as public. That’s why it’s called Revealing Module pattern. For example:\r\n\r\nconst myRevealingModule = (function() {\r\n  \r\n  let privateVar = \'Peter\';\r\n  const publicVar  = \'Hello World\';\r\n  function privateFunction() {\r\n    console.log(\'Name: \'+ privateVar);\r\n  }\r\n  \r\n  function publicSetName(name) {\r\n    privateVar = name;\r\n  }\r\n  function publicGetName() {\r\n    privateFunction();\r\n  }\r\n  /** reveal methods and variables by assigning them to object     properties */\r\nreturn {\r\n    setName: publicSetName,\r\n    greeting: publicVar,\r\n    getName: publicGetName\r\n  };\r\n})();\r\nmyRevealingModule.setName(\'Mark\');\r\n// prints Name: Mark\r\nmyRevealingModule.getName();\r\nThis pattern makes it easier to understand which of our functions and variables can be accessed publicly, which helps in code readability.\r\n\r\nAfter the code is executed, the myRevealingModule looks like this:\r\n\r\nconst myRevealingModule = {\r\n  setName: publicSetName,\r\n  greeting: publicVar,\r\n  getName: publicGetName\r\n};\r\nWe can call myRevealingModule.setName(\'Mark\'), which is a reference to the inner publicSetName and myRevealingModule.getName(), which is a reference to the inner publicGetName. For example:\r\n\r\nmyRevealingModule.setName(\'Mark\');\r\n// prints Name: Mark\r\nmyRevealingModule.getName();\r\nAdvantages of Revealing Module pattern over Module Pattern:\r\n\r\nWe can change members from public to private and vice versa by modifying a single line in the return statement.\r\nThe returned object contains no function definitions, all right-hand side expressions are defined inside the IIFE, making the code clear and easy to read.\r\nES6 Modules\r\nBefore ES6, JavaScript didn’t have built-in modules, so developers had to rely on third-party libraries or the module pattern to implement modules. But with ES6, JavaScript has native modules.\r\n\r\nES6 modules are stored in files. There can only be one module per file. Everything inside a module is private by default. Functions, variables, and classes are exposed using the export keyword. The code inside a module always runs in strict mode.\r\n\r\nExporting a Module\r\nThere are two ways to export a function and variable declaration:\r\n\r\nBy adding the export keyword in front of function and variable declaration. For example:\r\n// utils.js\r\nexport const greeting = \'Hello World\';\r\nexport function sum(num1, num2) {\r\n  console.log(\'Sum:\', num1, num2);\r\n  return num1 + num2;\r\n}\r\nexport function subtract(num1, num2) {\r\n  console.log(\'Subtract:\', num1, num2);\r\n  return num1 - num2;\r\n}\r\n// This is a private function\r\nfunction privateLog() {\r\n  console.log(\'Private Function\');\r\n}\r\nBy adding the export keyword at end of the code containing names of functions and variables we want to export. For example:\r\n// utils.js\r\nfunction multiply(num1, num2) {\r\n  console.log(\'Multiply:\', num1, num2);\r\n  return num1 * num2;\r\n}\r\nfunction divide(num1, num2) {\r\n  console.log(\'Divide:\', num1, num2);\r\n  return num1 / num2;\r\n}\r\n// This is a private function\r\nfunction privateLog() {\r\n  console.log(\'Private Function\');\r\n}\r\nexport {multiply, divide};\r\nImporting a Module\r\nSimilar to exporting a module, there are two ways to import a module by using the import keyword. For example:\r\n\r\nImporting multiple items at one time\r\n// main.js\r\n// importing multiple items\r\nimport { sum, multiply } from \'./utils.js\';\r\nconsole.log(sum(3, 7));\r\nconsole.log(multiply(3, 7));\r\nImporting all of a module\r\n// main.js\r\n// importing all of module\r\nimport * as utils from \'./utils.js\';\r\nconsole.log(utils.sum(3, 7));\r\nconsole.log(utils.multiply(3, 7));\r\nImports and Exports can be aliased\r\nIf you want to avoid naming collisions, you can change the name of export both during export as well as import. For example:\r\n\r\nRenaming an export\r\n// utils.js\r\nfunction sum(num1, num2) {\r\n  console.log(\'Sum:\', num1, num2);\r\n  return num1 + num2;\r\n}\r\nfunction multiply(num1, num2) {\r\n  console.log(\'Multiply:\', num1, num2);\r\n  return num1 * num2;\r\n}\r\nexport {sum as add, multiply};\r\nRenaming an import\r\n// main.js\r\nimport { add, multiply as mult } from \'./utils.js\';\r\nconsole.log(add(3, 7));\r\nconsole.log(mult(3, 7));\r\nSingleton Pattern\r\nA Singleton is an object which can only be instantiated only once. A singleton pattern creates a new instance of a class if one doesn’t exist. If an instance exists, it simply returns a reference to that object. Any repeated calls to the constructor would always fetch the same object.\r\n\r\nJavaScript has always had singletons built-in to the language. We just don’t call them singletons, we call them object literal. For example:\r\n\r\nconst user = {\r\n  name: \'Peter\',\r\n  age: 25,\r\n  job: \'Teacher\',\r\n  greet: function() {\r\n    console.log(\'Hello!\');\r\n  }\r\n};\r\nBecause each object in JavaScript occupies a unique memory location and when we call the user object, we are essentially returning reference to this object.\r\n\r\nIf we try to copy the user variable into another variable and modify that variable. For example:\r\n\r\nconst user1 = user;\r\nuser1.name = \'Mark\';\r\nWe would see both of objects are modified because objects in JavaScript are passed by reference not by value. So there is only a single object in the memory. For example:\r\n\r\n// prints \'Mark\'\r\nconsole.log(user.name);\r\n// prints \'Mark\'\r\nconsole.log(user1.name);\r\n// prints true\r\nconsole.log(user === user1);\r\nSingleton pattern can be implemented using the constructor function. For example:\r\n\r\nlet instance = null;\r\nfunction User() {\r\n  if(instance) {\r\n    return instance;\r\n  }\r\n  instance = this;\r\n  this.name = \'Peter\';\r\n  this.age = 25;\r\n  \r\n  return instance;\r\n}\r\nconst user1 = new User();\r\nconst user2 = new User();\r\n// prints true\r\nconsole.log(user1 === user2); \r\nWhen this constructor function is called, it checks if the instance object exists or not. If the object doesn’t exist, it assigns the this variable to the instance variable. And if the object exists, it just returns that object.\r\n\r\nSingletons can also be implemented using the module pattern. For example:\r\n\r\nconst singleton = (function() {\r\n  let instance;\r\n  \r\n  function init() {\r\n    return {\r\n      name: \'Peter\',\r\n      age: 24,\r\n    };\r\n  }\r\n  return {\r\n    getInstance: function() {\r\n      if(!instance) {\r\n        instance = init();\r\n      }\r\n      \r\n      return instance;\r\n    }\r\n  }\r\n})();\r\nconst instanceA = singleton.getInstance();\r\nconst instanceB = singleton.getInstance();\r\n// prints true\r\nconsole.log(instanceA === instanceB);\r\nIn the above code, we are creating a new instance by calling the singleton.getInstance method. If an instance already exists, this method simply returns that instance, if the instance doesn’t exist, it creates a new instance by calling the init() function.\r\n\r\nLearn more at: https://blog.bitsrc.io/understanding-design-patterns-in-javascript-13345223f2dd', 'learning.jpg', 'learning_thumb.jpg', 39, 12);
INSERT INTO `articles` (`title`, `date`, `description`, `img`, `thumbnail`, `id`, `author_id`) VALUES
('How I earned $15,000 last month from freelance design', '2019-04-07 04:42:25', '*** Update ***\r\nI’ve written a follow-up piece about what I’ve done to sustain these freelance earnings over the long-term. Please also read How I earned $150K last year from freelance design.\r\n\r\nI just sent off over NZ$15,000 worth in invoices for freelance design work performed last month. It might have been my most lucrative month ever. I’d like to talk about what’s making this period profitable for me, and share how I’ve gotten to this point in my design career.\r\n\r\nI’m a freelance UI/UX designer in Auckland, New Zealand. I’ve been doing it since 2001?—?starting part time as a student and then building my freelance business into a full time gig shortly after graduating. I’ve never been employed. This is all I’ve ever known.\r\n\r\nI’m a T shaped individual with a broad range of design experience, but my bread and butter is in providing tremendous value to my clients all the way through a product, app, or website’s creation cycle: right from initial strategy, through IA and UX design, and UI design. I often do front-end code too, and sometimes even development.\r\n\r\nWhat I didn’t do\r\nHow did I set a personal best in monthly freelance earnings?\r\n\r\nI didn’t work insane long hours, burning the candle at both ends and burning myself out in the process. In fact, my normal work day is 9:30–5:00 with a comfortable lunch break in between. I occasionally work a bit in the evenings, but that’s the exception not the norm.\r\n\r\nI have a wife and two kids who I spend a lot of time with. I exercise before work each morning to keep healthy, and even find time to meditate now and then. By no means is the balance of my life suffering just to earn a lot of money. Life is too important (and money not important enough) for me to do that.\r\n\r\nI didn’t churn out work as quickly as possible to maximise profits on fixed project quotes. Nor did I subcontract work to cheaper creatives so I can reap the profits of marked up labour. Everything I do is of the utmost quality, performed by me, every time.\r\n\r\nI didn’t even make passive income. None. My last passive income side project was sold over a year ago and I haven’t yet launched a new one.\r\n\r\nEvery dollar earned was directly tied to hours worked, for a handful of fantastic clients.\r\n\r\nAre you working for cost-clients or value-clients?\r\n\r\nKnowing the difference will mean everything to your freelance business.\r\nmedium.com	\r\nIt’s all about reputation\r\nEarning good money as a freelancer starts with having great clients. I’ve spent my entire career defining who my ideal clients are, and then working towards landing those projects. There is no magic bullet here. Without a stroke of luck, rookie freelancers don’t land the kind of clients they dream of. Everyone successful in this business has been willing to put in the work to get there.\r\n\r\nMore than anything else, this requires building a reputation. As a freelancer you live and die by it. The foundation of that reputation is doing excellent work, over and over again. Every client deserves your best effort. Deliver it every time. Your clients will be thrilled with your service, and eventually they’ll talk. They’ll tell their family, friend, and colleagues about you, and boom?—?more work.\r\n\r\nWord of mouth referrals are the bee’s knees. Of course you’ve heard this before, but have you really thought about what it means?\r\n\r\nIf you’re shopping for a new car, computer, doctor, or lawyer, you asked people you trust for their recommendations. You take their recommendations as a starting point, do a bit of your own research to validate them, and then commit to one of the recommendations.\r\n\r\nWhy? Because if you trust who it’s coming from, and they say it’s good, then you trust that it’s good. You are pre-qualified to trust that recommendation based on the weight of trust you have with the human it came from. You usually don’t bother looking into alternatives outside of what was recommended.\r\n\r\nWhen I get a referral from an old client in this way, the new client comes to me already respecting my expertise and experience, trusting my process, and eager to work with me. There is no hard sell required. Usually no sell at all. My reputation has already sealed the deal.\r\n\r\nIn fact, I’ve had word of mouth clients delay their project for months until I become available, because they consider working with me essential to their project’s success. After all, working with the right people is always more important than niggling over price or timing. If a new client believes you’re the right person, you’ve won yourself a potential unicorn.\r\n\r\nWhy being ultra-professional instantly makes you a top-tier freelancer\r\n\r\nMore than mastery of your craft or years of experience, being a trustworthy pro gets you a big step ahead of your…\r\nmedium.com	\r\nWhat if I never get word of mouth referrals?\r\nYou will over time. But if you’re not quite there yet, don’t fret.\r\n\r\nYou can still build the same level of trust very early in the relationship, and reap the same benefits.\r\n\r\nI’m currently working on a job for a small web dev agency. They recently lost their full time designer and were looking to hire a new one. I told them I wasn’t interested in a full time position, but I’d happy help them fill the gap by contracting to them for a few projects until they found a new designer to fill the role.\r\n\r\nI met with them once for 45 minutes. They asked me questions about my process and experience, and I answered honestly. I asked them some in return. I walked them through a few of my case studies, explaining the design challenges of each one and justified my solutions.\r\n\r\nAfter the meeting they told me they were giving up on hiring a new designer right away. They said I had raised the bar of what their expectations of a senior designer should be, and none of the people they had been interviewing came even close.\r\n\r\nThat one meeting instilled so much trust that they wanted me on their next available job.\r\n\r\nAll it takes is one phone call or meeting to give people confidence in what you do. You just have to know what to say! That’s a topic for its own article, but if you’re confident in your own process and abilities, just be yourself. Be 100% open and honest about how you work, and if they know what they are looking for, that genuine interaction will shine through.\r\n\r\nTakeaway lesson:\r\nYour reputation is what earns the trust and respect of great clients. Nurture that reputation, always. If you haven’t been doing it since day one, start now. No amount of effort put into building your reputation is wasted effort.\r\n\r\nI’m self-employed, but I don’t “freelance”\r\n\r\nCan independent consultants escape this medieval term for mercenaries?\r\nmedium.com	\r\nCharge what you think you’re worth.\r\nNow add at least 20% more.\r\nWarning: what follows is actual talk about real dollar figures. Yes, it’s OK to talk about money.\r\n\r\nAll of my current projects are billing within the range of NZ$120–$150 per hour + GST. (For non NZ/AUS folks that’s “Goods and Service Tax”, similar to sales tax. It’s 15% here). Newer jobs are generally $130–$150 while some older clients are still on $120. I also charge on the lower end of that spectrum when subcontracting to an agency, as they generally need more room to mark up.\r\n\r\nA few years ago I believed I was hitting a ceiling at around NZ$100 per hour. I hadn’t raised my rates much in years, despite a tremendous amount of additional experience and efficiencies gained during that time. When talking to a few colleagues I realised that ceiling was all in my head. I was producing work as good or better than most agencies turn out, so why couldn’t I start charging closer to their $150-$200 rates?\r\n\r\nThe answer is, I could. There was no reason not to. I raised my rates 20% overnight (and more since then), and never had a decrease in clients knocking on my door. If anything, it led to more clients.\r\n\r\nThe foundation for a high-end rates comes back to having a rock-solid reputation, and from doing truly world-class work, over and over. You have to hone the skills and gain experience enough to justify those prices.\r\n\r\nWhat to charge as a freelancer: does value-based pricing live up to the hype?\r\n\r\nMy thoughts on value-based pricing and what I do instead\r\nmedium.freecodecamp.org	\r\nHow do you know if you can justify it?\r\nSimply put, do your clients feel like they are getting good value from you? That’s it. Ask them straight up if their behaviour doesn’t make the answer obvious.\r\n\r\nIf they keep coming back for more, the answer is yes. If at the end of the project you go your separate ways and never hear from them again, then maybe not.\r\n\r\nTakeaway lesson:\r\nResearch pricing in your industry and location. Know how you fit into that market. Do your skills and experience align with that position you sit? If you work quickly and efficiently compared to your peers, consider how that may give your clients more value, and increase your rate accordingly. Don’t be afraid to test the waters. You can always reduce your rate if an increase fails.\r\n\r\nEmbrace long, complex jobs.\r\nOver the last few years I’ve been doing more and more work designing web apps. Big, complex, responsive web apps. The kind of jobs that may take 2+ months just on IA, user flows, and UX wireframes before you even get into the visual design. The kinds of jobs that might last a year of continuous work.\r\n\r\nThat’s right, a year.\r\n\r\nA few years ago I did design and front-end for a web app and its marketing site. The project lasted almost exactly a year, including some add-ons like branding, print design, banners, etc.\r\n\r\nAt the moment I’m in the middle of another similarly sized job. We’re over six months into it, and while the end is in sight, there’s still a long way to get there. It may very well end up being a year from start to finish, with smaller pieces of ongoing work after.\r\n\r\nI hear you saying it already:\r\n\r\n“A year long project! I would get bored. It would get stale. I became a freelancer precisely to get away from that kind of work!”\r\nI agree. Those were my concerns as well.\r\n\r\nPart of the reason I love freelancing is the freedom it brings of choosing your clients and projects, which more often than not means choosing variety, trying new things, pushing your limits.\r\n\r\nNo matter how passionate you are about the project, and genuinely interested you are in success of the business, when you get six or nine months into it, you can start to lose enthusiasm.\r\n\r\nHowever, these long engagements are well worth it! They provide consistency in scheduling, workload, and income?—?all things that even the most seasoned freelancers struggle to maintain.\r\n\r\nHere’s what I do to make those long but ultimately fruitful projects remain interesting all the way to the finish line:\r\n\r\nAlways be working on two or three projects at once. I find it’s rarely possible for a single project to have enough workload and a quick enough feedback/iteration cycle for it to be full-time. I divide my workload between two or three jobs running in parallel, which makes a good balance that keeps them all moving along at decent velocity. My clients have a clear expectation up front of how much of my time I can devote to their project. Setting client expectations early and often is key to making this work.\r\nBuild variety into your work by being choosy about what projects you take on. If I’m 6 months into a complex web app interface design, the last things I want is another similar project. I’ll go out of my way to look for something on the opposite end of the spectrum to balance it?—?perhaps a really visual brochure or ecommerce site. Something with a smaller timeframe that will let me flex a different set of design muscles for a while. That may mean turning down great jobs for clients I love, but maintaining joy in my work is more important.\r\nGet invested in your client’s success. Really, seriously interested and passionate about it. This starts with picking clients who run businesses you admire and can find some personal interest in. You need to build up your career to a point where you can afford to turn down a lot of work so you can be very choosy about what you accept. Only accept work that aligns with your interests, strengths, and ethics so you can confidently invest yourself into the process and outcomes. I know this is a luxury that many people don’t have, and I feel privileged to have it. If you don’t have that luxury, start small. That first little “no” may empower you to say the next harder “no”, which paves the path to choosing your ideal projects.\r\nControl the process so it doesn’t control you. Remember, your client isn’t usually an expert in design. They are looking to you to outline the best creative process for how you achieve their goals. Setup a process that works well for you and know how to justify that process. This is important because it means you always feel you are doing something valuable and worthwhile. You are always on the right trajectory towards the finish line. There’s nothing worse than doing work you feel isn’t worth doing.\r\nIf you can balance all of those things, taking on steady, high-paying, year-long projects with clients who completely trust you is a great step towards making bank as a freelancer. It’s a heck a lot easier than finding an endless supply of new clients with small month-long jobs.\r\n\r\nfor more information go at https://medium.com/swlh/how-i-earned-15-000-last-month-from-freelance-design-7f359d6776b', 'earn.jpeg', 'earn_thumb.jpeg', 40, 12),
('Rendering on the Web', '2019-04-07 04:45:58', 'As developers, we are often faced with decisions that will affect the entire architecture of our applications. One of the core decisions web developers must make is where to implement logic and rendering in their application. This can be a difficult, since there are a number of different ways to build a website.\r\n\r\nOur understanding of this space is informed by our work in Chrome talking to large sites over the past few years. Broadly speaking, we would encourage developers to consider server rendering or static rendering over a full rehydration approach.\r\n\r\nIn order to better understand the architectures we’re choosing from when we make this decision, we need to have a solid understanding of each approach and consistent terminology to use when speaking about them. The differences between these approaches help illustrate the trade-offs of rendering on the web through the lens of performance.\r\n\r\nTerminology\r\nRendering\r\n\r\nSSR: Server-Side Rendering - rendering a client-side or universal app to HTML on the server.\r\nCSR: Client-Side Rendering - rendering an app in a browser, generally using the DOM.\r\nRehydration: “booting up” JavaScript views on the client such that they reuse the server-rendered HTML’s DOM tree and data.\r\nPrerendering: running a client-side application at build time to capture its initial state as static HTML.\r\nPerformance\r\n\r\nTTFB: Time to First Byte - seen as the time between clicking a link and the first bit of content coming in.\r\nFP: First Paint - the first time any pixel gets becomes visible to the user.\r\nFCP: First Contentful Paint - the time when requested content (article body, etc) becomes visible.\r\nTTI: Time To Interactive - the time at which a page becomes interactive (events wired up, etc).\r\nServer Rendering\r\nServer rendering generates the full HTML for a page on the server in response to navigation. This avoids additional round-trips for data fetching and templating on the client, since it’s handled before the browser gets a response.\r\n\r\nServer rendering generally produces a fast First Paint (FP) and First Contentful Paint (FCP). Running page logic and rendering on the server makes it possible to avoid sending lots of JavaScript to the client, which helps achieve a fast Time to Interactive (TTI). This makes sense, since with server rendering you’re really just sending text and links to the user’s browser. This approach can work well for a large spectrum of device and network conditions, and opens up interesting browser optimizations like streaming document parsing.\r\n\r\nDiagram showing server rendering and JS execution affecting FCP and TTI\r\n\r\nWith server rendering, users are unlikely to be left waiting for CPU-bound JavaScript to process before they can use your site. Even when third-party JS can’t be avoided, using server rendering to reduce your own first-party JS costs can give you more \"budget\" for the rest. However, there is one primary drawback to this approach: generating pages on the server takes time, which can often result in a slower Time to First Byte (TTFB).\r\n\r\nWhether server rendering is enough for your application largely depends on what type of experience you are building. There is a longstanding debate over the correct applications of server rendering versus client-side rendering, but it’s important to remember that you can opt to use server rendering for some pages and not others. Some sites have adopted hybrid rendering techniques with success. Netflix server-renders its relatively static landing pages, while prefetching the JS for interaction-heavy pages, giving these heavier client-rendered pages a better chance of loading quickly.\r\n\r\nMany modern frameworks, libraries and architectures make it possible to render the same application on both the client and the server. These techniques can be used for Server Rendering, however it’s important to note that architectures where rendering happens both on the server and on the client are their own class of solution with very different performance characteristics and tradeoffs. React users can use renderToString() or solutions built atop it like Next.js for server rendering. Vue users can look at Vue’s server rendering guide or Nuxt. Angular has Universal. Most popular solutions employ some form of hydration though, so be aware of the approach in use before selecting a tool.\r\n\r\nStatic Rendering\r\nStatic rendering happens at build-time and offers a fast First Paint, First Contentful Paint and Time To Interactive - assuming the amount of client-side JS is limited. Unlike Server Rendering, it also manages to achieve a consistently fast Time To First Byte, since the HTML for a page doesn’t have to be generated on the fly. Generally, static rendering means producing a separate HTML file for each URL ahead of time. With HTML responses being generated in advance, static renders can be deployed to multiple CDNs to take advantage of edge-caching.\r\n\r\nDiagram showing static rendering and optional JS execution affecting FCP\r\nand TTI\r\n\r\nSolutions for static rendering come in all shapes and sizes. Tools like Gatsby are designed to make developers feel like their application is being rendered dynamically rather than generated as a build step. Others like Jekyl and Metalsmith embrace their static nature, providing a more template-driven approach.\r\n\r\nOne of the downsides to static rendering is that individual HTML files must be generated for every possible URL. This can be challenging or even infeasible when you can\'t predict what those URLs will be ahead of time, or for sites with a large number of unique pages.\r\n\r\nReact users may be familiar with Gatsby, Next.js static export or Navi - all of these make it convenient to author using components. However, it’s important to understand the difference between static rendering and prerendering: static rendered pages are interactive without the need to execute much client-side JS, whereas prerendering improves the First Paint or First Contentful Paint of a Single Page Application that must be booted on the client in order for pages to be truly interactive.\r\n\r\nIf you’re unsure whether a given solution is static rendering or prerendering, try this test: disable JavaScript and load the created web pages. For statically rendered pages, most of the functionality will still exist without JavaScript enabled. For prerendered pages, there may still be some basic functionality like links, but most of the page will be inert.\r\n\r\nAnother useful test is to slow your network down using Chrome DevTools, and observe how much JavaScript has been downloaded before a page becomes interactive. Prerendering generally requires more JavaScript to get interactive, and that JavaScript tends to be more complex than the Progressive Enhancement approach used by static rendering.\r\n\r\nServer Rendering vs Static Rendering\r\nServer rendering is not a silver bullet - its dynamic nature can come with significant compute overhead costs. Many server rendering solutions don\'t flush early, can delay TTFB or double the data being sent (e.g. inlined state used by JS on the client). In React, renderToString() can be slow as it\'s synchronous and single-threaded. Getting server rendering \"right\" can involve finding or building a solution for component caching, managing memory consumption, applying memoization techniques, and many other concerns. You\'re generally processing/rebuilding the same application multiple times - once on the client and once in the server. Just because server rendering can make something show up sooner doesn\'t suddenly mean you have less work to do.\r\n\r\nServer rendering produces HTML on-demand for each URL but can be slower than just serving static rendered content. If you can put in the additional leg-work, server rendering + HTML caching can massively reduce server render time. The upside to server rendering is the ability to pull more \"live\" data and respond to a more complete set of requests than is possible with static rendering. Pages requiring personalization are a concrete example of the type of request that would not work well with static rendering.\r\n\r\nServer rendering can also present interesting decisions when building a PWA. Is it better to use full-page service worker caching, or just server-render individual pieces of content?\r\n\r\nClient-Side Rendering (CSR)\r\nClient-side rendering (CSR) means rendering pages directly in the browser using JavaScript. All logic, data fetching, templating and routing are handled on the client rather than the server.\r\n\r\nClient-side rendering can be difficult to get and keep fast for mobile. It can approach the performance of pure server-rendering if doing minimal work, keeping a tight JavaScript budget and delivering value in as few RTTs as possible. Critical scripts and data can be delivered sooner using HTTP/2 Server Push or <link rel=preload>, which gets the parser working for you sooner. Patterns like PRPL are worth evaluating in order to ensure initial and subsequent navigations feel instant.\r\n\r\nDiagram showing client-side rendering affecting FCP and TTI\r\n\r\nThe primary downside to Client-Side Rendering is that the amount of JavaScript required tends to grow as an application grows. This becomes especially difficult with the addition of new JavaScript libraries, polyfills and third-party code, which compete for processing power and must often be processed before a page’s content can be rendered. Experiences built with CSR that rely on large JavaScript bundles should consider aggressive code-splitting, and be sure to lazy-load JavaScript - \"serve only what you need, when you need it\". For experiences with little or no interactivity, server rendering can represent a more scalable solution to these issues.\r\n\r\nFor folks building a Single Page Application, identifying core parts of the User Interface shared by most pages means you can apply the Application Shell caching technique. Combined with service workers, this can dramatically improve perceived performance on repeat visits.\r\n\r\nCombining server rendering and CSR via rehydration\r\nOften referred to as Universal Rendering or simply “SSR”, this approach attempts to smooth over the trade-offs between Client-Side Rendering and Server Rendering by doing both. Navigation requests like full page loads or reloads are handled by a server that renders the application to HTML, then the JavaScript and data used for rendering is embedded into the resulting document. When implemented carefully, this achieves a fast First Contentful Paint just like Server Rendering, then “picks up” by rendering again on the client using a technique called (re)hydration. This is a novel solution, but it can have some considerable performance drawbacks.\r\n\r\nThe primary downside of SSR with rehydration is that it can have a significant negative impact on Time To Interactive, even if it improves First Paint. SSR’d pages often look deceptively loaded and interactive, but can’t actually respond to input until the client-side JS is executed and event handlers have been attached. This can take seconds or even minutes on mobile.\r\n\r\nPerhaps you’ve experienced this yourself - for a period of time after it looks like a page has loaded, clicking or tapping does nothing. This quickly becoming frustrating... “Why is nothing happening? Why can’t I scroll?”\r\n\r\nA Rehydration Problem: One App for the Price of Two\r\nRehydration issues can often be worse than delayed interactivity due to JS. In order for the client-side JavaScript to be able to accurately “pick up” where the server left off without having to re-request all of the data the server used to render its HTML, current SSR solutions generally serialize the response from a UI’s data dependencies into the document as script tags. The resulting HTML document contains a high level of duplication:\r\n\r\nRendering on the Web\r\nJason Miller\r\nBy Jason Miller\r\nJason is a Web DevRel\r\n \r\nAddy Osmani\r\nBy Addy Osmani\r\nEng Manager, Web Developer Relations\r\nAs developers, we are often faced with decisions that will affect the entire architecture of our applications. One of the core decisions web developers must make is where to implement logic and rendering in their application. This can be a difficult, since there are a number of different ways to build a website.\r\n\r\nOur understanding of this space is informed by our work in Chrome talking to large sites over the past few years. Broadly speaking, we would encourage developers to consider server rendering or static rendering over a full rehydration approach.\r\n\r\nIn order to better understand the architectures we’re choosing from when we make this decision, we need to have a solid understanding of each approach and consistent terminology to use when speaking about them. The differences between these approaches help illustrate the trade-offs of rendering on the web through the lens of performance.\r\n\r\nTerminology\r\nRendering\r\n\r\nSSR: Server-Side Rendering - rendering a client-side or universal app to HTML on the server.\r\nCSR: Client-Side Rendering - rendering an app in a browser, generally using the DOM.\r\nRehydration: “booting up” JavaScript views on the client such that they reuse the server-rendered HTML’s DOM tree and data.\r\nPrerendering: running a client-side application at build time to capture its initial state as static HTML.\r\nPerformance\r\n\r\nTTFB: Time to First Byte - seen as the time between clicking a link and the first bit of content coming in.\r\nFP: First Paint - the first time any pixel gets becomes visible to the user.\r\nFCP: First Contentful Paint - the time when requested content (article body, etc) becomes visible.\r\nTTI: Time To Interactive - the time at which a page becomes interactive (events wired up, etc).\r\nServer Rendering\r\nServer rendering generates the full HTML for a page on the server in response to navigation. This avoids additional round-trips for data fetching and templating on the client, since it’s handled before the browser gets a response.\r\n\r\nServer rendering generally produces a fast First Paint (FP) and First Contentful Paint (FCP). Running page logic and rendering on the server makes it possible to avoid sending lots of JavaScript to the client, which helps achieve a fast Time to Interactive (TTI). This makes sense, since with server rendering you’re really just sending text and links to the user’s browser. This approach can work well for a large spectrum of device and network conditions, and opens up interesting browser optimizations like streaming document parsing.\r\n\r\nDiagram showing server rendering and JS execution affecting FCP and TTI\r\n\r\nWith server rendering, users are unlikely to be left waiting for CPU-bound JavaScript to process before they can use your site. Even when third-party JS can’t be avoided, using server rendering to reduce your own first-party JS costs can give you more \"budget\" for the rest. However, there is one primary drawback to this approach: generating pages on the server takes time, which can often result in a slower Time to First Byte (TTFB).\r\n\r\nWhether server rendering is enough for your application largely depends on what type of experience you are building. There is a longstanding debate over the correct applications of server rendering versus client-side rendering, but it’s important to remember that you can opt to use server rendering for some pages and not others. Some sites have adopted hybrid rendering techniques with success. Netflix server-renders its relatively static landing pages, while prefetching the JS for interaction-heavy pages, giving these heavier client-rendered pages a better chance of loading quickly.\r\n\r\nMany modern frameworks, libraries and architectures make it possible to render the same application on both the client and the server. These techniques can be used for Server Rendering, however it’s important to note that architectures where rendering happens both on the server and on the client are their own class of solution with very different performance characteristics and tradeoffs. React users can use renderToString() or solutions built atop it like Next.js for server rendering. Vue users can look at Vue’s server rendering guide or Nuxt. Angular has Universal. Most popular solutions employ some form of hydration though, so be aware of the approach in use before selecting a tool.\r\n\r\nStatic Rendering\r\nStatic rendering happens at build-time and offers a fast First Paint, First Contentful Paint and Time To Interactive - assuming the amount of client-side JS is limited. Unlike Server Rendering, it also manages to achieve a consistently fast Time To First Byte, since the HTML for a page doesn’t have to be generated on the fly. Generally, static rendering means producing a separate HTML file for each URL ahead of time. With HTML responses being generated in advance, static renders can be deployed to multiple CDNs to take advantage of edge-caching.\r\n\r\nDiagram showing static rendering and optional JS execution affecting FCP\r\nand TTI\r\n\r\nSolutions for static rendering come in all shapes and sizes. Tools like Gatsby are designed to make developers feel like their application is being rendered dynamically rather than generated as a build step. Others like Jekyl and Metalsmith embrace their static nature, providing a more template-driven approach.\r\n\r\nOne of the downsides to static rendering is that individual HTML files must be generated for every possible URL. This can be challenging or even infeasible when you can\'t predict what those URLs will be ahead of time, or for sites with a large number of unique pages.\r\n\r\nReact users may be familiar with Gatsby, Next.js static export or Navi - all of these make it convenient to author using components. However, it’s important to understand the difference between static rendering and prerendering: static rendered pages are interactive without the need to execute much client-side JS, whereas prerendering improves the First Paint or First Contentful Paint of a Single Page Application that must be booted on the client in order for pages to be truly interactive.\r\n\r\nIf you’re unsure whether a given solution is static rendering or prerendering, try this test: disable JavaScript and load the created web pages. For statically rendered pages, most of the functionality will still exist without JavaScript enabled. For prerendered pages, there may still be some basic functionality like links, but most of the page will be inert.\r\n\r\nAnother useful test is to slow your network down using Chrome DevTools, and observe how much JavaScript has been downloaded before a page becomes interactive. Prerendering generally requires more JavaScript to get interactive, and that JavaScript tends to be more complex than the Progressive Enhancement approach used by static rendering.\r\n\r\nServer Rendering vs Static Rendering\r\nServer rendering is not a silver bullet - its dynamic nature can come with significant compute overhead costs. Many server rendering solutions don\'t flush early, can delay TTFB or double the data being sent (e.g. inlined state used by JS on the client). In React, renderToString() can be slow as it\'s synchronous and single-threaded. Getting server rendering \"right\" can involve finding or building a solution for component caching, managing memory consumption, applying memoization techniques, and many other concerns. You\'re generally processing/rebuilding the same application multiple times - once on the client and once in the server. Just because server rendering can make something show up sooner doesn\'t suddenly mean you have less work to do.\r\n\r\nServer rendering produces HTML on-demand for each URL but can be slower than just serving static rendered content. If you can put in the additional leg-work, server rendering + HTML caching can massively reduce server render time. The upside to server rendering is the ability to pull more \"live\" data and respond to a more complete set of requests than is possible with static rendering. Pages requiring personalization are a concrete example of the type of request that would not work well with static rendering.\r\n\r\nServer rendering can also present interesting decisions when building a PWA. Is it better to use full-page service worker caching, or just server-render individual pieces of content?\r\n\r\nClient-Side Rendering (CSR)\r\nClient-side rendering (CSR) means rendering pages directly in the browser using JavaScript. All logic, data fetching, templating and routing are handled on the client rather than the server.\r\n\r\nClient-side rendering can be difficult to get and keep fast for mobile. It can approach the performance of pure server-rendering if doing minimal work, keeping a tight JavaScript budget and delivering value in as few RTTs as possible. Critical scripts and data can be delivered sooner using HTTP/2 Server Push or <link rel=preload>, which gets the parser working for you sooner. Patterns like PRPL are worth evaluating in order to ensure initial and subsequent navigations feel instant.\r\n\r\nDiagram showing client-side rendering affecting FCP and TTI\r\n\r\nThe primary downside to Client-Side Rendering is that the amount of JavaScript required tends to grow as an application grows. This becomes especially difficult with the addition of new JavaScript libraries, polyfills and third-party code, which compete for processing power and must often be processed before a page’s content can be rendered. Experiences built with CSR that rely on large JavaScript bundles should consider aggressive code-splitting, and be sure to lazy-load JavaScript - \"serve only what you need, when you need it\". For experiences with little or no interactivity, server rendering can represent a more scalable solution to these issues.\r\n\r\nFor folks building a Single Page Application, identifying core parts of the User Interface shared by most pages means you can apply the Application Shell caching technique. Combined with service workers, this can dramatically improve perceived performance on repeat visits.\r\n\r\nCombining server rendering and CSR via rehydration\r\nOften referred to as Universal Rendering or simply “SSR”, this approach attempts to smooth over the trade-offs between Client-Side Rendering and Server Rendering by doing both. Navigation requests like full page loads or reloads are handled by a server that renders the application to HTML, then the JavaScript and data used for rendering is embedded into the resulting document. When implemented carefully, this achieves a fast First Contentful Paint just like Server Rendering, then “picks up” by rendering again on the client using a technique called (re)hydration. This is a novel solution, but it can have some considerable performance drawbacks.\r\n\r\nThe primary downside of SSR with rehydration is that it can have a significant negative impact on Time To Interactive, even if it improves First Paint. SSR’d pages often look deceptively loaded and interactive, but can’t actually respond to input until the client-side JS is executed and event handlers have been attached. This can take seconds or even minutes on mobile.\r\n\r\nPerhaps you’ve experienced this yourself - for a period of time after it looks like a page has loaded, clicking or tapping does nothing. This quickly becoming frustrating... “Why is nothing happening? Why can’t I scroll?”\r\n\r\nA Rehydration Problem: One App for the Price of Two\r\nRehydration issues can often be worse than delayed interactivity due to JS. In order for the client-side JavaScript to be able to accurately “pick up” where the server left off without having to re-request all of the data the server used to render its HTML, current SSR solutions generally serialize the response from a UI’s data dependencies into the document as script tags. The resulting HTML document contains a high level of duplication:\r\n\r\nHTML document\r\ncontaining serialized UI, inlined data and a bundle.js script\r\n\r\nAs you can see, the server is returning a description of the application’s UI in response to a navigation request, but it’s also returning the source data used to compose that UI, and a complete copy of the UI’s implementation which then boots up on the client. Only after bundle.js has finished loading and executing does this UI become interactive.\r\n\r\nPerformance metrics collected from real websites using SSR rehydration indicate its use should be heavily discouraged. Ultimately, the reason comes down to User Experience: it\'s extremely easy to end up leaving users in an “uncanny valley”.\r\n\r\nDiagram showing client rendering negatively affecting TTI\r\n\r\nThere’s hope for SSR with rehydration, though. In the short term, only using SSR for highly cacheable content can reduce the TTFB delay, producing similar results to prerendering. Rehydrating incrementally, progressively, or partially may be the key to making this technique more viable in the future.\r\n\r\nStreaming server rendering and Progressive Rehydration\r\nServer rendering has had a number of developments over the last few years.\r\n\r\nStreaming server rendering allows you to send HTML in chunks that the browser can progressively render as it\'s received. This can provide a fast First Paint and First Contentful Paint as markup arrives to users faster. In React, streams being asynchronous in renderToNodeStream() - compared to synchronous renderToString - means backpressure is handled well.\r\n\r\nProgressive rehydration is also worth keeping an eye on, and something React has been exploring. With this approach, individual pieces of a server-rendered application are “booted up” over time, rather than the current common approach of initializing the entire application at once. This can help reduce the amount of JavaScript required to make pages interactive, since client-side upgrading of low priority parts of the page can be deferred to prevent blocking the main thread. It can also help avoid one of the most common SSR Rehydration pitfalls, where a server-rendered DOM tree gets destroyed and then immediately rebuilt - most often because the initial synchronous client-side render required data that wasn’t quite ready, perhaps awaiting Promise resolution.\r\n\r\nPartial Rehydration\r\nPartial rehydration has proven difficult to implement. This approach is an extension of the idea of progressive rehydration, where the individual pieces (components / views / trees) to be progressively rehydrated are analyzed and those with little interactivity or no reactivity are identified. For each of these mostly-static parts, the corresponding JavaScript code is then transformed into inert references and decorative functionality, reducing their client-side footprint to near-zero. The partial hydration approach comes with its own issues and compromises. It poses some interesting challenges for caching, and client-side navigation means we can\'t assume server-rendered HTML for inert parts of the application will be available without a full page load.\r\n\r\nTrisomorphic Rendering\r\nIf service workers are an option for you, “trisomorphic” rendering may also be of interest. It\'s a technique where you can use streaming server rendering for initial/non-JS navigations, and then have your service worker take on rendering of HTML for navigations after it has been installed. This can keep cached components and templates up to date and enables SPA-style navigations for rendering new views in the same session. This approach works best when you can share the same templating and routing code between the server, client page, and service worker.\r\n\r\nDiagram of Trisomorphic rendering, showing a browser and service worker\r\ncommunicating with the server\r\n\r\nSEO Considerations\r\nTeams often factor in the impact of SEO when choosing a strategy for rendering on the web. Server-rendering is often chosen for delivering a \"complete looking\" experience crawlers can interpret with ease. Crawlers may understand JavaScript, but there are often limitations worth being aware of in how they render. Client-side rendering can work but often not without additional testing and leg-work. More recently dynamic rendering has also become an option worth considering if your architecture is heavily driven by client-side JavaScript.\r\n\r\nWhen in doubt, the Mobile Friendly Test tool is invaluable for testing that your chosen approach does what you\'re hoping for. It shows a visual preview of how any page appears to Google\'s crawler, the serialized HTML content found (after JavaScript executed), and any errors encountered during rendering. for more information go at https://developers.google.com/web/updates/2019/02/rendering-on-the-web', 'render.jpg', 'render_thumb.jpg', 41, 12);

-- --------------------------------------------------------

--
-- Table structure for table `ci_sessions`
--

CREATE TABLE `ci_sessions` (
  `id` varchar(40) NOT NULL,
  `ip_address` varchar(45) NOT NULL,
  `timestamp` int(10) UNSIGNED NOT NULL DEFAULT '0',
  `data` blob NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

-- --------------------------------------------------------

--
-- Table structure for table `tank_login_attempts`
--

CREATE TABLE `tank_login_attempts` (
  `id` int(11) NOT NULL,
  `ip_address` varchar(40) COLLATE utf8_bin NOT NULL,
  `login` varchar(50) COLLATE utf8_bin NOT NULL,
  `time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;

--
-- Dumping data for table `tank_login_attempts`
--

INSERT INTO `tank_login_attempts` (`id`, `ip_address`, `login`, `time`) VALUES
(1, '::1', 'admin2', '2019-04-07 02:30:40'),
(2, '::1', 'admin2', '2019-04-07 02:32:25'),
(3, '::1', 'admin2', '2019-04-07 02:33:20'),
(4, '::1', 'admin2', '2019-04-07 02:33:24'),
(5, '::1', 'admin2', '2019-04-07 02:33:40');

-- --------------------------------------------------------

--
-- Table structure for table `tank_users`
--

CREATE TABLE `tank_users` (
  `id` int(11) NOT NULL,
  `username` varchar(50) COLLATE utf8_bin NOT NULL,
  `password` varchar(255) COLLATE utf8_bin NOT NULL,
  `email` varchar(100) COLLATE utf8_bin NOT NULL,
  `activated` tinyint(1) NOT NULL DEFAULT '1',
  `banned` tinyint(1) NOT NULL DEFAULT '0',
  `ban_reason` varchar(255) COLLATE utf8_bin DEFAULT NULL,
  `new_password_key` varchar(50) COLLATE utf8_bin DEFAULT NULL,
  `new_password_requested` datetime DEFAULT NULL,
  `new_email` varchar(100) COLLATE utf8_bin DEFAULT NULL,
  `new_email_key` varchar(50) COLLATE utf8_bin DEFAULT NULL,
  `last_ip` varchar(40) COLLATE utf8_bin NOT NULL,
  `last_login` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',
  `created` datetime NOT NULL DEFAULT '0000-00-00 00:00:00',
  `modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;

--
-- Dumping data for table `tank_users`
--

INSERT INTO `tank_users` (`id`, `username`, `password`, `email`, `activated`, `banned`, `ban_reason`, `new_password_key`, `new_password_requested`, `new_email`, `new_email_key`, `last_ip`, `last_login`, `created`, `modified`) VALUES
(9, 'reynald', '$2a$08$ME4Rg.xiRohnbnleYcz0G.9EH/TW9gcll58mblcrBm/RRCb7epSZO', 'reynald@yahoo.com', 1, 0, NULL, NULL, NULL, NULL, NULL, '::1', '2019-04-07 17:24:32', '2019-04-07 04:54:07', '2019-04-07 15:24:32'),
(10, 'admin4', '$2a$08$j/VoAPoUTiBA2ZgOexAbu.U1nWGhdHu0BlI6.hfwVoZbB0IuyC5e.', 'admin4@gmail.com', 1, 0, NULL, NULL, NULL, NULL, NULL, '::1', '0000-00-00 00:00:00', '2019-04-07 04:55:22', '2019-04-07 02:55:22'),
(11, 'Anthony', '$2a$08$Qlb4DTPhH.ChVvQAiAZHuezJnrJt/n5L.qD8H/8DqRzyNMid2XYYu', 'anthony@gmail.com', 1, 0, NULL, NULL, NULL, NULL, NULL, '::1', '2019-04-07 05:07:58', '2019-04-07 05:07:47', '2019-04-07 03:07:58'),
(12, 'alluysios', '$2a$08$7wA9GcrCf093egDmcikh2eC/x0E3TiLxWbklNDqytACv2KRwvmAUa', 'alluysios@gmail.com', 1, 0, NULL, NULL, NULL, NULL, NULL, '::1', '2019-04-07 05:45:47', '2019-04-07 05:45:08', '2019-04-07 03:45:47');

-- --------------------------------------------------------

--
-- Table structure for table `tank_user_autologin`
--

CREATE TABLE `tank_user_autologin` (
  `key_id` char(32) COLLATE utf8_bin NOT NULL,
  `user_id` int(11) NOT NULL DEFAULT '0',
  `user_agent` varchar(150) COLLATE utf8_bin NOT NULL,
  `last_ip` varchar(40) COLLATE utf8_bin NOT NULL,
  `last_login` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;

-- --------------------------------------------------------

--
-- Table structure for table `tank_user_profiles`
--

CREATE TABLE `tank_user_profiles` (
  `id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `country` varchar(20) COLLATE utf8_bin DEFAULT NULL,
  `website` varchar(255) COLLATE utf8_bin DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;

--
-- Dumping data for table `tank_user_profiles`
--

INSERT INTO `tank_user_profiles` (`id`, `user_id`, `country`, `website`) VALUES
(1, 1, NULL, NULL),
(2, 2, NULL, NULL),
(3, 3, NULL, NULL),
(4, 4, NULL, NULL),
(5, 5, NULL, NULL),
(6, 6, NULL, NULL),
(7, 9, NULL, NULL),
(8, 10, NULL, NULL),
(9, 11, NULL, NULL),
(10, 12, NULL, NULL);

--
-- Indexes for dumped tables
--

--
-- Indexes for table `articles`
--
ALTER TABLE `articles`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `ci_sessions`
--
ALTER TABLE `ci_sessions`
  ADD PRIMARY KEY (`id`),
  ADD KEY `ci_sessions_timestamp` (`timestamp`);

--
-- Indexes for table `tank_login_attempts`
--
ALTER TABLE `tank_login_attempts`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `tank_users`
--
ALTER TABLE `tank_users`
  ADD PRIMARY KEY (`id`);

--
-- Indexes for table `tank_user_autologin`
--
ALTER TABLE `tank_user_autologin`
  ADD PRIMARY KEY (`key_id`,`user_id`);

--
-- Indexes for table `tank_user_profiles`
--
ALTER TABLE `tank_user_profiles`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `articles`
--
ALTER TABLE `articles`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=42;

--
-- AUTO_INCREMENT for table `tank_login_attempts`
--
ALTER TABLE `tank_login_attempts`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=6;

--
-- AUTO_INCREMENT for table `tank_users`
--
ALTER TABLE `tank_users`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=13;

--
-- AUTO_INCREMENT for table `tank_user_profiles`
--
ALTER TABLE `tank_user_profiles`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=11;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
